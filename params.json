{
  "name": "15418-project",
  "tagline": "Final project for CMU 15-418.",
  "body": "## Proposal\r\n### Summary\r\nOriginally, the project was going to be implementing (portions of) [CloudLight](https://research.nvidia.com/publication/cloudlight-system-amortizing-indirect-lighting-real-time-rendering/) with the intent of multi-viewport rendering. The primary interest was the global illumination algorithm based around creating irradiance maps as it strikes a balance between local and remote computation, as well as not requiring too much network bandwidth. \r\n\r\nKayvon suggested I try to consider Yong's SPIRE system and implement a cloud context into the pipeline. Supposedly that alone is enough for a project? Or I will hook his system into Vulkan or write a scheduler for it? I'm not exactly sure what I'm doing anymore. \r\n\r\nI am talking to Yong on Monday to get a better idea.\r\n### Background\r\nOriginally:\r\n\r\nCloud rendering is a promising platform for graphics rendering in the future. Rendering (games) in the cloud has the potential for methods that would be unreasonable for a local machine, such as possibly raytracing the entire scene to achieve a higher level of quality.\r\n\r\n### Challenge\r\nOriginally:\r\n\r\nLaunching a separate instance of a raytracer for every viewport is clearly inefficient if multiple viewports are sharing a scene. We need to break down the problem into portions that are viewport independent and those that aren't, allowing us to amortize the cost of operations across many viewports. Global illumination is one component of a scene that is viewport independent, and as such can be amortized across clients.\r\n\r\nThe CloudLight paper by NVIDIA proposes several methods for amortizing global illumination.\r\n\r\nNotable challenges would be the amount of components that need to be implemented: a remote side raytracer, networking code, as well as the client side code to piece information together and incorporate it into its rendering pipeline.\r\n\r\n### Resources\r\nOriginally:\r\n\r\nIn a similar vein to the paper, multiple frameworks would be used to speed up development times of the various components.\r\n\r\nRaytracing  -   OptiX\r\nNetworking  -   Asio / SDL_net\r\nWindow      -   SDL / GLFW\r\nGraphics    -   OpenGL\r\nH.264       -   C++ / libav / FFmpeg\r\n\r\nClient side would probably be my laptop. Access to a machine with a beefy GPU that I could run at a whim (Gates / latedays / other) would be used for the cloud side.\r\n\r\nCode would be written from scratch.\r\n\r\n### Goals and Deliverables\r\nOriginally:\r\n\r\nPlan to achieve:\r\nDemonstrate a system with multiple viewports interacting with a single remote server, and compare performance to a system where work is not amortized.\r\n\r\nHope to achieve:\r\nImplement this in to Yong's system\r\n\r\n\r\nCurrently:\r\n\r\n\r\n\r\n### Schedule\r\nApril 1: Become confused\r\n\r\nApril 4: Talk to Yong\r\n\r\nApril 5: Talk to Kayvon\r\n\r\nApril 5: Formulate a concrete project idea\r\n\r\nOriginally:\r\n\r\nApril 9: Crude raytracer in OptiX\r\n\r\nApril 16: Crude renderer in OpenGL\r\n\r\nApril 22: Irradiance map creation in OptiX\r\n\r\nApril 29: Implement irradiance map in OpenGL\r\n\r\nMay 6: Communication code between host and client\r\n\r\nMay 9: Feel accomplished",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}